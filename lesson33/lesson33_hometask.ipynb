{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hometask\n",
    "\n",
    "1) Find text to train (any book)<br>\n",
    "2) Build train and validation set <br>\n",
    "3) Train bidirectional language model that predicts the POS of word being based on its `n_context= 3` neighbours from the left and `n_context= 3` neighbours from the right <br>\n",
    "4) Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'Siaiuchyi_shliakh.txt'\n",
    "\n",
    "import codecs\n",
    "fileObj = codecs.open( \"Siaiuchyi_shliakh.txt\", \"r\", \"utf_8_sig\" )\n",
    "text = fileObj.read()\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDS(Dataset):\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.text = re.sub(r'\\[.*\\]', \"\", self.text)\n",
    "        self.text = re.sub(r'\\d+', \"\", self.text)\n",
    "        self.text = re.sub(r'«|»', \"\", self.text)\n",
    "        vectorizer = CountVectorizer(token_pattern=r'(?u)(?:\\b\\w+\\b|\\.|\\,|\\!|\\?|\\-|\\n)').fit([self.text])\n",
    "        self.vocab_arr = vectorizer.get_feature_names_out()\n",
    "        self.w2i = vectorizer.vocabulary_\n",
    "        self.i2w = {v: k for k, v in self.w2i.items()}\n",
    "        word_tokenizer = vectorizer.build_tokenizer()\n",
    "        raw_tokens = word_tokenizer(text)\n",
    "        tokens = sorted(set(raw_tokens))\n",
    "        step = 1 # shift to build new sample\n",
    "        self.contexts = []\n",
    "        self.targets = []\n",
    "        self.n_context = 7\n",
    "        for i in range(0, len(raw_tokens) - self.n_context, step):\n",
    "            context_tokens = [token.lower() for token in raw_tokens[i: i + self.n_context]]\n",
    "            context_tokens.pop(self.n_context // 2)\n",
    "            context_tokens = [token for token in context_tokens if token in self.w2i]\n",
    "            if len(context_tokens) != self.n_context - 1:\n",
    "                continue\n",
    "            target_index = i + self.n_context // 2\n",
    "            target_word = raw_tokens[target_index].lower()\n",
    "            if target_word in self.w2i:\n",
    "                self.targets.append(target_word)\n",
    "                self.contexts.append(context_tokens)\n",
    "            else:\n",
    "                print(f\"there '{target_word}' no in voc\")\n",
    "        self.embedding_dim = 10\n",
    "        self.embedded = nn.Embedding(len(tokens), self.embedding_dim)\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        for context in self.contexts:\n",
    "            context_indices = [self.w2i[token] for token in context]\n",
    "            context_embedding = self.embedded(torch.tensor(context_indices))\n",
    "            self.x.append(context_embedding)\n",
    "        target_indices = [self.w2i[target] for target in self.targets]\n",
    "        self.y = torch.tensor(target_indices)\n",
    "        #self.y = [y.unsqueeze(0) for y in self.y]\n",
    "        #print({self.y.shape})\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.contexts)\n",
    "    \n",
    "    def preprocess(self,text):\n",
    "        text = re.sub(r'\\[.*\\]', \"\", text)\n",
    "        text = re.sub(r'\\d+', \"\", text)\n",
    "        text = re.sub(r'«|»', \"\", text)\n",
    "        vectorizer = CountVectorizer(token_pattern=r'(?u)(?:\\b\\w+\\b|\\.|\\,|\\!|\\?|\\-|\\n)').fit([text])\n",
    "        word_tokenizer = vectorizer.build_tokenizer()\n",
    "        raw_tokens = word_tokenizer(text)\n",
    "        token_indices = [self.w2i[token.lower()] for token in raw_tokens if token.lower() in self.w2i]\n",
    "        \n",
    "        return torch.tensor(token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there '11' no in voc\n",
      "there '180' no in voc\n",
      "there '2001' no in voc\n",
      "there '200' no in voc\n",
      "there '1111' no in voc\n",
      "there '50' no in voc\n",
      "there '1943' no in voc\n",
      "there '60' no in voc\n",
      "there '11' no in voc\n",
      "there '11' no in voc\n",
      "there '11' no in voc\n",
      "there '1240' no in voc\n",
      "there '2' no in voc\n",
      "there '19' no in voc\n",
      "there '1' no in voc\n",
      "there '2' no in voc\n",
      "there '3' no in voc\n",
      "there '40' no in voc\n",
      "there '16а2' no in voc\n",
      "there '11' no in voc\n",
      "there '15' no in voc\n",
      "there '2002' no in voc\n",
      "there '11' no in voc\n",
      "there '11' no in voc\n",
      "there '11' no in voc\n",
      "there '1137' no in voc\n",
      "there '11' no in voc\n",
      "there '200' no in voc\n",
      "there '25' no in voc\n",
      "there '2' no in voc\n",
      "there '1986' no in voc\n",
      "there '1992' no in voc\n",
      "there '1998' no in voc\n",
      "there '1' no in voc\n",
      "there '2' no in voc\n",
      "there '3' no in voc\n",
      "there '35' no in voc\n",
      "there '150' no in voc\n",
      "there '180' no in voc\n",
      "there '145' no in voc\n",
      "there '20' no in voc\n",
      "there '20' no in voc\n",
      "there '100' no in voc\n",
      "there '7' no in voc\n",
      "there '9' no in voc\n",
      "there '80' no in voc\n",
      "there '16' no in voc\n",
      "there '16' no in voc\n",
      "there '10' no in voc\n",
      "there '24' no in voc\n",
      "there '280' no in voc\n",
      "there '4' no in voc\n",
      "there '100' no in voc\n",
      "there '250' no in voc\n",
      "there '12' no in voc\n",
      "there '500' no in voc\n",
      "there '1200' no in voc\n",
      "there '27' no in voc\n",
      "there '170' no in voc\n",
      "there '36' no in voc\n",
      "there '525' no in voc\n",
      "there '99' no in voc\n",
      "there '140' no in voc\n",
      "there '71' no in voc\n",
      "there '1917' no in voc\n",
      "there '75' no in voc\n",
      "there '75' no in voc\n",
      "there '200' no in voc\n",
      "there '60' no in voc\n",
      "there '400' no in voc\n",
      "there '5' no in voc\n",
      "there '50' no in voc\n",
      "there '50' no in voc\n",
      "there '7' no in voc\n",
      "there '45' no in voc\n",
      "there '15' no in voc\n",
      "there '8' no in voc\n",
      "there '1942' no in voc\n",
      "there '12' no in voc\n",
      "there '45' no in voc\n",
      "there '45' no in voc\n",
      "there '1986' no in voc\n",
      "there '1991' no in voc\n",
      "there '90' no in voc\n",
      "there '1992' no in voc\n",
      "there '45' no in voc\n",
      "there 'ф1' no in voc\n",
      "there '19' no in voc\n",
      "there '1848' no in voc\n",
      "there '1933' no in voc\n",
      "there '1991' no in voc\n",
      "there '2001' no in voc\n",
      "there '2003' no in voc\n",
      "there '1' no in voc\n",
      "there '50' no in voc\n",
      "there '1793' no in voc\n",
      "there '30' no in voc\n",
      "there '40' no in voc\n",
      "there '60' no in voc\n",
      "there '15' no in voc\n",
      "there '1941' no in voc\n",
      "there '1848' no in voc\n",
      "there '25' no in voc\n"
     ]
    }
   ],
   "source": [
    "ds=TextDS(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print({ds[1337][0].shape}, {ds[1337][1].shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  # 2 for bidirectional\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # 2 for bidirectional\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "seq_length = 6\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = len(ds.vocab_arr)\n",
    "\n",
    "\n",
    "model = BiRNN(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "batch_size = 64 \n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,shuffle=True)\n",
    "test_loader= DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    tqdm_loader = tqdm(dataloader, unit=\"batch\", desc=f\"Epoch {epoch}\", total=len(dataloader))\n",
    "    for batch, (X, y) in enumerate(tqdm_loader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            tqdm_loader.set_postfix(loss=loss.item())\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1143/1143 [00:23<00:00, 49.65batch/s, loss=6.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 16.7%, Avg loss: 7.073682 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1143/1143 [00:14<00:00, 80.64batch/s, loss=6.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 17.0%, Avg loss: 7.326131 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1143/1143 [00:13<00:00, 82.76batch/s, loss=5.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 7.829980 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1143/1143 [00:13<00:00, 82.64batch/s, loss=5.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 16.1%, Avg loss: 8.392230 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1143/1143 [00:13<00:00, 81.79batch/s, loss=3.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 16.0%, Avg loss: 8.881456 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1143/1143 [00:14<00:00, 81.47batch/s, loss=3.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.3%, Avg loss: 9.296077 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1143/1143 [00:14<00:00, 80.71batch/s, loss=3.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.8%, Avg loss: 9.608563 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1143/1143 [00:13<00:00, 81.91batch/s, loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 9.963832 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1143/1143 [00:13<00:00, 82.43batch/s, loss=3.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.0%, Avg loss: 10.307096 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1143/1143 [00:13<00:00, 82.24batch/s, loss=2.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.4%, Avg loss: 10.457911 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1143/1143 [00:13<00:00, 83.55batch/s, loss=2.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.0%, Avg loss: 10.731898 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1143/1143 [00:14<00:00, 80.96batch/s, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 14.9%, Avg loss: 10.975221 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1143/1143 [00:13<00:00, 82.73batch/s, loss=2.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 11.148243 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1143/1143 [00:13<00:00, 83.17batch/s, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 11.306624 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1143/1143 [00:14<00:00, 81.46batch/s, loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 15.0%, Avg loss: 11.512945 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "for t in range(n_epochs):\n",
    "    train_loop(train_loader, model, criterion, optimizer, epoch=t)\n",
    "    test_loop(test_loader, model, criterion)\n",
    "\n",
    "torch.save(model, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
